{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U0mak-kJurj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "WgPGm27Ca6b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv('/content/sql_create_context.csv')\n",
        "df_2 = pd.read_csv('/content/synthetic_text_to_sql.csv')"
      ],
      "metadata": {
        "id": "xn9Zc3GzLikA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing"
      ],
      "metadata": {
        "id": "e2Or5AJGa4qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add `;` to dataset 1"
      ],
      "metadata": {
        "id": "md-K8xZLc1UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1['context'] = df_1['context'] + \";\"\n",
        "df_1['answer'] = df_1['answer'] + \";\""
      ],
      "metadata": {
        "id": "62nDdTSqYw9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove `INSERT INTO` statements in dataset 2"
      ],
      "metadata": {
        "id": "JekIJ7-Fc0TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_insert_statements(sql):\n",
        "    return re.sub(r'INSERT INTO.*?;', '', sql, flags=re.DOTALL)\n",
        "\n",
        "df_2['sql_context'] = df_2['sql_context'].apply(remove_insert_statements)"
      ],
      "metadata": {
        "id": "cILOFCQbcxI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we merge both datasets"
      ],
      "metadata": {
        "id": "XSnWuaTJfmdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.columns = ['prompt','context','answer']\n",
        "df_2.columns = ['prompt','context','answer']\n",
        "\n",
        "df = pd.concat([df_1, df_2], ignore_index=True)\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df = df.loc[~df['context'].isin([\"\",\" \"])]"
      ],
      "metadata": {
        "id": "9V6KP5nafxt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train, validation and test datasets"
      ],
      "metadata": {
        "id": "uyxWPleQiHWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 75% for training\n",
        "train_df, temp_df = train_test_split(df, test_size=0.25, random_state=42)\n",
        "\n",
        "# 15% for validation, 10% for testing\n",
        "validation_df, test_df = train_test_split(temp_df, test_size=0.4, random_state=42)\n",
        "\n",
        "print(\"Training set size:\", len(train_df))\n",
        "print(\"Validation set size:\", len(validation_df))\n",
        "print(\"Test set size:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OHWOYndiJuo",
        "outputId": "f9f82de0-626c-46a9-f9d4-e847d6962fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 133920\n",
            "Validation set size: 26784\n",
            "Test set size: 17856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing"
      ],
      "metadata": {
        "id": "ikHblniAfkr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_df.to_csv('validation.csv', index=False)"
      ],
      "metadata": {
        "id": "ekuho1uelALD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('test.csv', index=False)"
      ],
      "metadata": {
        "id": "fpX-NFjzlHYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('train.csv', index=False)"
      ],
      "metadata": {
        "id": "PtS5BUunCrJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp train.csv \"/content/drive/My Drive/text2sql_data/\"\n",
        "!cp test.csv \"/content/drive/My Drive/text2sql_data/\"\n",
        "!cp validation.csv \"/content/drive/My Drive/text2sql_data/\""
      ],
      "metadata": {
        "id": "RQ_hBZFVCvxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}